# Quotes

https://arxiv.org/pdf/1903.06281

- "While research on AI does occasionally refer to models of child development and learning, it usually does so without addressing—or interrogating—parenting practices."
- "In human children, there is evidence that all sorts of stimuli, from exposure to racist behaviour (Feagan and Ausdale 2001) to television reports of violence (Pfefferbaum et al. 2001), can either traumatise children or teach them to internalise and reproduce harmful patterns."
- "As Anima Anandkumar (interviewed in Simonite 2018) argues, the lack of diversity in the field is likely to increase the risk that potential harms of AI will not be noticed until products are released."
- Sandry (2015) argues, with specific reference to social robots, that we should welcome opportunities to communicate across, and learn from, irreducible difference.
- Similarly, Lewis et al. (2018) offer multiple visions of kinship relationships with AI that are based on reciprocity and respect with non-human others.
- "But if, as parents, we intend to follow such a path, we should also do our best to ensure that the realisation is not surprising or traumatising." *In the context of turning off the AI*
- Algorithms are, in the current paradigm, predominantly mechanisms of control. They are used to manage not only tiny things like the data in computers, but now access to vital resources like healthcare and housing, as well as being deployed in systems of policing and militarisation (Eubanks 2018).
- Parents must find a way to navigate the reality of having the power to provide or withhold even the most basic needs from their children, as well as finding ways to nurture children’s autonomy and, at the same time, protecting them from outside harms and preventing them from harming others.
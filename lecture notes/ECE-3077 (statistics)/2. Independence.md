# 2. Independence


Two events $A$ and $B$ are **independent** if:

$$P(A \cap B ) = P(A) P(B)$$


If $X \subset Y$, then the two are not independent. It really comes down to: if knowing one probability influences the probability of something else, then the two are not independent. 


#### Example:

Given:

$$B_1 = B_2 = \{0, 1\}$$

$$P(B_1=0)=P(B_2=0)= 0.5$$

This is equivalent to a coin flip pretty much. $B_1$ and $B_2$ are independent. Then, look at:

$$Z = B_1 \oplus B_2$$

Would this be independent of $B_1$ and $B_2$? 


| $B_1$ | $B_2$ | $Z$ |
| ----- | ----- | --- |
| 0     | 0     | 0   |
| 0     | 1     | 1   |
| 1     | 0     | 1   |
| 1     | 1     | 0   |

From this table, it's evident that $P(Z=0)=0.5$. Now, notice that if you are told what $B_1$ or (but not both) $B_2$ is, you gain no new information about the probability of $Z$; it will still be a 50% chance. For this reason, Z is actually independent of $B_1$ and $B_2$ 


---

You can have pairwise independence, but not group independence. However, the metric of independence remains unchanged for multiple probabilities:

$$P(A_1 \cap A_2 \cap \dots \cap A_n) = P(A_1)P(A_2)\cdots P(A_n)$$

> So, pairwise independence doesn't guarantee group independence, but does group independence guarantee pair independence?


### Conditional Probability

Conditional probability gives the probability of an event $A$, given the occurrence of an event $B$. 

$$P(A|B) = \frac{P(A\cap B)}{P(B)}$$

It's important to note:

$$P(A|B) \ne P(B|A)$$

---

For independent events, you can say:

$$P(A \cap B) = P(A) \cdot P(B)$$

But, for conditional probability, you need to change this to:

$$P(A\cap B) =P(B) \cdot  P(A | B) = P(A) \cdot P(B|A)$$

You can derive these from the equation above.

--- 

The **multiplication rule** for *independent events*  is:

$$P\left(\bigcap \limits_{i=1}^n A_i \right) = \prod _{i=1}^n P(A_i)$$

Or, for *conditional events*:

$$P \left ( \bigcap_{i=1}^n A_i \right) = P(A_1)\cdot P(A_2|A_1) \cdots P(A_n| A_1 \cap \cdots \cap A_{n-1})$$


For example, for *three events* you would get:

$$P(A_1 \cap A_2 \cap A_3) = P(A_1) P(A_2|A_3) P(A_3|A_1 \cap A_2)$$

---

The **total probability theorem** states that:

If $A_1, A_2, \dots, A_n$ are *disjoint events* that fully partition the space $\Omega$, meaning that $\Omega = A_1 \cup A_2 \cup \dots \cup A_n$ , then:

$$P(B) = P(A_1 \cap B) + \cdots + P(A_n\cap B)$$

Then, using the definition of conditional probability, this can be re-expressed as:

$$P(B) = P(B|A_1) P(A_1) + \cdots + P(B| A_n) P(A_n)$$
$$= \sum _{i=1}^n P(B|A_i)P(A_i)$$


Where $B \subset \Omega$ :

![](excalidraw-2025-08-27-12.45.11.excalidraw.svg)
%%[ðŸ–‹ Edit in Excalidraw](excalidraw-2025-08-27-12.45.11.excalidraw.md)%%

### Example

> Robert is the star quarterback for your favorite football team. His knee is bothering him, and so there is only a 40% chance he plays in the next game. If he plays, the probability that your team wins is 0.75. If he does not, it is only 0.35. What is the probability that your team wins the game.


- $A$ = Robert Plays
- $A^c$ = Robert does not play
- $B$ = Wins the game

Thus,

$$P(B) = P(A) P(B|A) + P(A^c) P(B|A^c) = (0.4)(0.75) + (0.6)(0.35) = 51\%$$

---

### Monty Hall Problem

The probability of you winning if you don't switch is:

$$
\begin{aligned}
P(B) = &P(B| Car @ D1) \cdot P(Car @ D1) \\
&+ P(B|Car @ D2) \cdot P(Car @ D2)\\ 
&+ P(B|Car @ D3)\cdot P(Car @ D3) \\
&= 1 \cdot \frac 13 + 0 \cdot \frac 13 + 0 \cdot \frac 13 = \frac 13
\end{aligned}
$$

Now, the probability if you don't switch is:

$$
\begin{aligned}
P(B) = &P(B| Car @ D1) \cdot P(Car @ D1) \\
&+ P(B| Car @ D2) \cdot P(Car @ D2)\\ 
&+ P(B|Car @ D3) \cdot P(Car @ D3) \\
&= 0 \cdot \frac 13 + 1 \cdot \frac 13 +  1 \cdot \frac 13 = \frac 23
\end{aligned}
$$

Therefore it is always advantageous to switch.


---

### Example

> Anders and Blake both have coolers; Anders' is filled with & sodas and 3 beers, while Blake's is filled with 2 sodas and 11 beers. The coolers look identical, so you just choose one at random and start pulling out drinks.
> 
> Suppose you pull out one drink. What is the probability that you pull out a soda?


- $S$ = Pull a soda
- $A$ = Choose Anders' cooler
- $B$ = Choose Blake's cooler

$$P(S) = P(S|A) P(A) + P(S|B)P(B)$$

We know:
- $P(A) = 1/2$
- $P(B) = 1/2$
- $P(S|A) = 8/11$
- $P(S|B) = 2/13$

So, $P(S) = \frac 12 \Big( \frac 8{11} \frac{2}{13}\Big) \approx = \_\_$

Now, *what if there are two sodas*?

- $S_1'$ is a soda on the first pull
- $S_2'$ is a soda on the second pull

We are trying to find:

$$P(S_1' \cap S_2 ' | A  ) = P(S_1'|A) \cdot P(S_2' | S_1' \cap A)$$

>  what the fuck is going on


### Bayes' Rule

$$P(A|B) = \frac{P(B|A)\cdot P(A)}{P(B)}$$

 This comes from the multiplication rule:

$$P(A \cap B) = P(A) P(B|A) =P (B) P(A|B)$$


---

### In-Class Example

- $R$ Robert Plays
- $R^c$ Robert does not play
- $W$ Team wins

Given:

- $P(W|R) = 0.75$
- $P(W|R^c) = 0.35$

Find:

$P(R|W)$ 


$$P(R|W) = \frac{P(W|R)\cdot P(R)}{P(W)}$$

Multiplication rule says:

$$P \left ( \bigcap_{i=1}^n A_i \right) = P(A_1)\cdot P(A_2|A_1) \cdots P(A_n| A_1 \cap \cdots \cap A_{n-1})$$

Or, in this case:


$$P(W) = P(W|R)\cdot P(R) + P(W|R^c)\cdot P(R^c)$$

So this is:

$$P(R|W) = \frac{P(W|R)\cdot P(R)}{P(W|R)\cdot P(R) + P(W|R^c)\cdot P(R^c)}$$


$$P(R|W) = \frac{(0.4)(0.75)}{(0.51)}\approx 0.588$$



---

### Example

> 10% of the population loves to read. However, 100% of librarians love to read.
>
> Librarians make up 0.04% of the population. Suppose I tell you that Rachel loves to read. What is the probability that she is a librarian?


- $A$ is a librarian (0.0004)
- $B$ likes to read (0.1)
- $P(B|A)=1$

What is $P(B|A^c)$:




Find $P(A|B)$

$$P(A|B) = \frac{P(B|A) P(A)}{P(B)}$$

$$= \frac{(1)(0.0004)}{0.1} = 0.004$$


#### confused

Where does this come from:

$$P(B) = P(B|A)P(A) + P(B|A^c)P(A^c)$$




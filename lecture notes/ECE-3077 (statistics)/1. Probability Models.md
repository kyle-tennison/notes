# 1. Probability Models


**Sample space** is $\Omega$ 
- This is every possible outcome

The **probability law** $P(\cdot)$ is the likelihood of different events

An **event** $A$ is a subspace of $\Omega$ 

For example:

$$\Omega = \{1,2,3,4,5,6\} $$

An event might be:
- The result is "1"; $A= \{1\}$ 
- The result is off; $A = \{1,3,5\}$
- The result is __ (anything is valid, so long that it is a subspace)


The *probability law* takes an event as a parameter, which is a subset of $\Omega$ 

$$P(\underbrace{\cdot}_{\text{event; subset of }\Omega} )$$

This law evaluates to a scalar, so for a die you may get something like:

$$P(\{1,3,5\}) = \frac{1}{2}$$

---

**Kolmogorov's probability axioms:**
1. Non-negativity: $P(A) \ge 0 \forall A$ 
2. Additivity: If $A$ and$B$ are disjoint (mutually exclusive), then $P(A \cup B) = P(A) + P(B)$ 
3. Normalization: $P(\Omega) = 1$ 

From these, you can derive the compliment rule:

$$1=P(\Omega) = P(A\cup A^c) = P(A) + P(A^c)$$
$$P(A^c)=1-P(A)$$

You can also say:


| More Properties                                                                    |
| ---------------------------------------------------------------------------------- |
| $$P(A_1\cup \cdots \cup A_n) = P(A_1)+P(A_2\cup\cdots \cup A_n) = \sum_i^nP(A_i)$$ |
| $$\text{If } A \subseteq B\text{, then } P(A) \le P(B)$$                           |
| $$P(A \cup B) = P(A)+P(B) - P(A \cap B)$$                                          |
| $$P(A\cup B) \le P(A) + P(B)$$                                                     |
| $$P(A\cup B \cup C) = P(A)+P(A^c \cap B) + P(A^c\cap B^c \cap C)$$                 |


---

### In-Class Example

> Out of the students in the class, 60% love soda, 70% love pizza, and 40%  love both soda and pizza. What is the probability that a randomly selected student loves neither soda nor pizza?


Let us define the sets:

- $A$ = loves soda
- $B$ = loves pizza
- $A \cap B$ = loves soda and pizza

We know that the union of those who love soda and pizza ($A \cup B$) is the number of everyone who likes either soda OR pizza OR both. Thus, the compliment of $A \cup B$, i.e. $(A \cup B)^c$ is the solution to our problem.

$$
P((A\cup B)^c) = 1 - P(A \cup B) = 1 - (P(A) + P(B) - P(A\cap B))
$$

Then, we are told: 
- $P(A) = 0.6$
- $P(B) = 0.7$
- $P(A\cap B) = 0.4$

Therefore, this is:

$$
P((A\cup B)^c) = 1 - (0.6 +0.7-0.4) = \underbrace{0.1}_{\text{Solution}}$$

---


### Types of models

There are 3 types of probability models:
1. Discrete and finite
2. Discrete and infinite 
3. Continuous 

#### Discrete Finite Models

$$|\Omega | = n$$
The size of the subset is some finite value $n$. The number of possible subsets is $2^n$. 

> Are these proper subsets or just subsets.

$\Omega$ can very easily get huge; for instance, the number of possible phone numbers.


#### Discrete Infinite Models

$$\Omega = \{1, 2, 3, \dots \} = \mathbb{N}$$

##### Example

This might be *"the number of coin flips until a tails is found."* There is, theoretically, no upper bound. 

Here, it happens that:

$$P(\text{\{k tosses until "tails"\}}) = P(k) = \left ( \frac{1}{2}\right)^k$$

Notice, it's important that:

$$\sum_{k=1}^\infty\left(\frac{1}{2} \right)^k = 1$$

Which satisfies the law of normalization. 

If, instead, the probability was *"the probability it takes at least 5 coin flips until a tails is found"*. We're now looking for

$$P(\{5,6,7,\dots\})$$

This would be:

$$P(\{5,6,7,\dots\}) = \sum_{k=5}^\infty \left(\frac 12 \right)^k = 1 - \sum_{k=1}^4\left(\frac 12 \right)^k = 1 - \left(\frac 12 + \frac 14 + \frac 18 + \frac 1{16} \right)= \frac{1}{16}$$
#### Continuous Models

There is a *continuum* of possible outcomes.

A simple example, if your choosing a number at random, the probability of that number being in some interval is the "length" of that interval, normalized to the size of $\Omega$. ^a


---

### Discrete uniform law

This states:

If $\Omega$ is finite with $|\Omega| = n$, then for any $A \subseteq \Omega$ , we can say:

$$P(A) = \frac{|A|}{|\Omega|}= \frac{\text{\# of elements in A}}{n}$$


(Don't overthink it)

---

You can expand this to the continuum to say something like, if $\Omega = \left[0, 1 \right]^2$ , then

$$P(A) = \frac{\text{Area}(A) }{\text{Area}(\Omega)}$$

This is related to [what I was saying earlier ](#^a)about the "length" of a 1D problem.


### In-Class example

> Han and Chewbacca have arranged to meet at the cantina at noon. Unfortunately, Han gets delayed by a bounty hunter and Chewbacca loses his watch, so they both are running late. Suppose that they both arrive with delays of anywhere from zero to two hours (with all possible delay combinations equally likely). Whoever gets there first will have a drink, wait for 20 minutes, and will leave if the other has not yet arrived. What is the probability that Han and Chewbacca meet?

![](excalidraw-2025-08-20-13.36.57.excalidraw.svg)
%%[ðŸ–‹ Edit in Excalidraw](excalidraw-2025-08-20-13.36.57.excalidraw.md)%%


# 4. Discrete Random Variables

A **random variable** $X$ is a mapping from the sample space $\Omega$ to the real line.

$$X: \Omega \to \mathbb R$$

It assigns a real number to every possible outcome. 

Examples:
- Number of M&Ms you pull until a repeated color
- Number of days until a part failure


### Notation
- Capital letters tend to denote random variables
- Lowercase letters tend to denote the particular outcomes a random variable might take. 

$$P(\{X=k\}) \qquad \text{for}\qquad k=1,2,\dots$$



The **probability mass function** relates to the fact that a random variable can be completely described by the probabilities of all the different values it can take. 

$$p_X(k) \equiv P(X=k)$$

For example, for a fair die:

$$p_X(k) = \{\frac 16 \qquad k=1,2,\dots,6$$

### Properties

Positivity:
$$\sum _k p_X(k) = 1$$


Normalization:
$$p_X(k)\ge 0 \forall k$$

### Bernoulli Random Variables

When $X$ is a binary value that's $1$ or $0$:

![[image-45.png|349x135]]


If you have $N$ events, $X_1, X_2, \dots , X_n$. 

$$X = \sum _i^nX_i = \text{\# of events w/ value 1 }$$

![[image-46.png]]


### Geometric Random Variables

If you do Bernoulli trials until you find a success, and let $X$ be the number of trials until finding a 1, you can say:

$$p_X(k) = (1-p)^{1-k}p \quad \text{for}\quad k=1,2,\dots$$

This is good if you want to find how many times you need to do something in order to see something. As $k \to \infty$, $p_X(k) \to 1$. 

"How many times will I flip this coin until I see a heads?" type shit.

### Poisson Random Variables

This is used mainly to model the probability of so many things happening in a given amount of time.

$$p_X(k) = e^{- \lambda} \frac{\lambda ^k}{k!}, \qquad k=0,1,2,\dots$$

where $\lambda$ is the *intensity parameter*. As $\lambda$ gets bigger, more events can happen in a given time.

### Functions of a Random Variable

We are free to define *another random variable* as a function of a random variable:

$$Y = g(X)$$

where $X$ is the original random variable being modified by $g()$ to get the new random variable $Y$. 

After making this change, we can say:

$$p_Y(y) = \sum _{\{k|g(k)=y\}} p_X(k)$$


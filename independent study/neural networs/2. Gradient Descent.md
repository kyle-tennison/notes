# 2. Gradient Descent


To start, assign all the weights randomly. Then, pass a sample to the network and compare the real output to the expected output. Then, *square the differences* in the two vectors, and then take the sum of the vector; this is the **cost** of the network, which roughly represents how poorly it preforms. If the cost is near zero, then the network preforms well.

If you preform this for many samples in a dataset, and take the average cost over each training sample, you can get an estimate of the performance of the network.

So now, you have some *function* whose parameters are all the weights and biases that returns a scalar that represents the performance of the network. We want to find the **minimum** of this function.

For a single-variable function, if you shift in the direction that the slope "points" (whichever direction is negative), you'll eventually find a local minimum. If your step size is proportional to the slope, as you approach the minimum, you'll get smaller and smaller steps and a more precise solution.

This approach doesn't guarantee a global minimumâ€”only a local minimum. Depending on where this iteration begins, you may get different minimums.

If you're working with a multivariable function, you can use the gradient to find the direction of quickest increase; going in the opposite direction will give the quickest decrease. 

If you assemble all weights and biases into a $1 \times n$ vector called $\textbf{W}$, then one iteration of the gradient descent will look like:

$$\textbf W_{i+1}=-\nabla C(\textbf W)$$

where $C$ is the cost.



### References

```vid
https://www.youtube.com/watch?v=IHZwWFHWa-w&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=2
Title: Gradient descent, how neural networks learn | DL2
Author: 3Blue1Brown
Thumbnail: https://i.ytimg.com/vi/IHZwWFHWa-w/mqdefault.jpg
AuthorUrl: https://www.youtube.com/@3blue1brown
```